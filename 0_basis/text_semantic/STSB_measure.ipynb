{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "verified-truth",
   "metadata": {},
   "source": [
    "# Semantic Textual Similarity\n",
    "Reference:\n",
    "* https://towardsdatascience.com/semantic-textual-similarity-83b3ca4a840e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "light-conference",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset stsb_multi_mt (/Users/llv23/.cache/huggingface/datasets/stsb_multi_mt/en/1.0.0/a5d260e4b7aa82d1ab7379523a005a366d9b124c76a5a5cf0c4c5365458b0ba9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ead7f0b365e43209bfe2fbb920a8e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5749, 3) (1379, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A girl is styling her hair.</td>\n",
       "      <td>A girl is brushing her hair.</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A group of men play soccer on the beach.</td>\n",
       "      <td>A group of boys are playing soccer on the beach.</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One woman is measuring another woman's ankle.</td>\n",
       "      <td>A woman measures another woman's ankle.</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man is cutting up a cucumber.</td>\n",
       "      <td>A man is slicing a cucumber.</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is playing a harp.</td>\n",
       "      <td>A man is playing a keyboard.</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentence1  \\\n",
       "0                    A girl is styling her hair.   \n",
       "1       A group of men play soccer on the beach.   \n",
       "2  One woman is measuring another woman's ankle.   \n",
       "3                A man is cutting up a cucumber.   \n",
       "4                       A man is playing a harp.   \n",
       "\n",
       "                                          sentence2  similarity_score  \n",
       "0                      A girl is brushing her hair.               2.5  \n",
       "1  A group of boys are playing soccer on the beach.               3.6  \n",
       "2           A woman measures another woman's ankle.               5.0  \n",
       "3                      A man is slicing a cucumber.               4.2  \n",
       "4                      A man is playing a keyboard.               1.5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Load the English STSB dataset\n",
    "stsb_dataset = load_dataset('stsb_multi_mt', 'en')\n",
    "stsb_train = pd.DataFrame(stsb_dataset['train'])\n",
    "stsb_test = pd.DataFrame(stsb_dataset['test'])\n",
    "\n",
    "# Check loaded data\n",
    "print(stsb_train.shape, stsb_test.shape)\n",
    "stsb_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valuable-feeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 13:07:18.758970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.10.1.dylib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def text_processing(sentence):\n",
    "    \"\"\"\n",
    "    Lemmatize, lowercase, remove numbers and stop words\n",
    "    \n",
    "    Args:\n",
    "      sentence: The sentence we want to process.\n",
    "    \n",
    "    Returns:\n",
    "      A list of processed words\n",
    "    \"\"\"\n",
    "    sentence = [token.lemma_.lower() for token in nlp(sentence) if token.is_alpha and not token.is_stop]\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def cos_sim(sentence1_emb, sentence2_emb):\n",
    "    \"\"\"\n",
    "    Cosine similarity between two columns of sentence embeddings\n",
    "    \n",
    "    Args:\n",
    "      sentence1_emb: sentence1 embedding column\n",
    "      sentence2_emb: sentence2 embedding column\n",
    "    \n",
    "    Returns:\n",
    "      The row-wise cosine similarity between the two columns.\n",
    "      For instance is sentence1_emb=[a,b,c] and sentence2_emb=[x,y,z]\n",
    "      Then the result is [cosine_similarity(a,x), cosine_similarity(b,y), cosine_similarity(c,z)]\n",
    "    \"\"\"\n",
    "    cos_sim = cosine_similarity(sentence1_emb, sentence2_emb)\n",
    "    return np.diag(cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-creek",
   "metadata": {},
   "source": [
    "## Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "round-firmware",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1379/1379 [00:16<00:00, 82.51it/s]\n"
     ]
    }
   ],
   "source": [
    "import textdistance\n",
    "\n",
    "def jaccard_sim(row):\n",
    "    # Text Processing\n",
    "    sentence1 = text_processing(row['sentence1'])\n",
    "    sentence2 = text_processing(row['sentence2'])\n",
    "    # Jaccard similarity\n",
    "    return textdistance.jaccard.normalized_similarity(sentence1, sentence2)\n",
    "\n",
    "# Jaccard Similarity\n",
    "stsb_test['Jaccard_score'] = stsb_test.progress_apply(jaccard_sim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "naked-vulnerability",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.500000\n",
       "1       0.666667\n",
       "2       1.000000\n",
       "3       0.500000\n",
       "4       0.500000\n",
       "          ...   \n",
       "1374    0.125000\n",
       "1375    0.200000\n",
       "1376    0.285714\n",
       "1377    0.071429\n",
       "1378    0.181818\n",
       "Name: Jaccard_score, Length: 1379, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsb_test['Jaccard_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-rocket",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "perfect-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "model = TfidfVectorizer(lowercase=True, stop_words='english')\n",
    "\n",
    "# Train the model\n",
    "X_train = pd.concat([stsb_train['sentence1'], stsb_train['sentence2']]).unique()\n",
    "model.fit(X_train)\n",
    "\n",
    "# Generate Embeddings on Test\n",
    "sentence1_emb = model.transform(stsb_test['sentence1'])\n",
    "sentence2_emb = model.transform(stsb_test['sentence2'])\n",
    "\n",
    "# Cosine Similarity\n",
    "stsb_test['TFIDF_cosine_score'] = cos_sim(sentence1_emb, sentence2_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decreased-checkout",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.490640\n",
       "1       0.613080\n",
       "2       0.705323\n",
       "3       0.692110\n",
       "4       0.349763\n",
       "          ...   \n",
       "1374    0.153509\n",
       "1375    0.287041\n",
       "1376    0.445120\n",
       "1377    0.000000\n",
       "1378    0.205252\n",
       "Name: TFIDF_cosine_score, Length: 1379, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsb_test['TFIDF_cosine_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-china",
   "metadata": {},
   "source": [
    "## Negative WMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adjusted-responsibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1379/1379 [00:18<00:00, 75.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = api.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "def word_movers_distance(row):\n",
    "    # Text Processing\n",
    "    sentence1 = text_processing(row['sentence1'])\n",
    "    sentence2 = text_processing(row['sentence2'])\n",
    "    # Negative Word Movers Distance\n",
    "    return -model.wmdistance(sentence1, sentence2)\n",
    "\n",
    "# Negative Word Movers Distance\n",
    "stsb_test['NegWMD_score'] = stsb_test.progress_apply(word_movers_distance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fundamental-plasma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.366527\n",
       "1      -0.161301\n",
       "2      -0.000000\n",
       "3      -0.292454\n",
       "4      -0.361692\n",
       "          ...   \n",
       "1374   -0.883562\n",
       "1375   -0.733618\n",
       "1376   -0.733277\n",
       "1377   -0.973450\n",
       "1378   -0.765407\n",
       "Name: NegWMD_score, Length: 1379, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsb_test['NegWMD_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-evidence",
   "metadata": {},
   "source": [
    "## USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "identified-integer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 16:41:36.457173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.dylib\n",
      "2022-04-28 16:41:36.457800: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: UNKNOWN ERROR (3)\n",
      "2022-04-28 16:41:36.459748: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: Orlando.localMac\n",
      "2022-04-28 16:41:36.459776: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: Orlando.localMac\n",
      "2022-04-28 16:41:36.463166: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-04-28 16:41:36.466807: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: Invalid argument: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got \"\"\n",
      "2022-04-28 16:41:36.477651: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-28 16:55:36.800085: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-28 16:55:41.243138: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Load the pre-trained model\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    # Control GPU memory usage\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "module_url = 'https://tfhub.dev/google/universal-sentence-encoder/4'\n",
    "model = hub.load(module_url)\n",
    "\n",
    "# Generate Embeddings\n",
    "sentence1_emb = model(stsb_test['sentence1']).numpy()\n",
    "sentence2_emb = model(stsb_test['sentence2']).numpy()\n",
    "\n",
    "# Cosine Similarity\n",
    "stsb_test['USE_cosine_score'] = cos_sim(sentence1_emb, sentence2_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "juvenile-apparatus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.737539\n",
       "1       0.889257\n",
       "2       0.856532\n",
       "3       0.907152\n",
       "4       0.620470\n",
       "          ...   \n",
       "1374    0.423459\n",
       "1375    0.648532\n",
       "1376    0.482272\n",
       "1377    0.251739\n",
       "1378    0.555975\n",
       "Name: USE_cosine_score, Length: 1379, dtype: float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsb_test['USE_cosine_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-scout",
   "metadata": {},
   "source": [
    "## Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pretty-junior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9047643edc84fd59d12c580d1de74b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6805793bbac4e5b8fc8717f0b7292c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/476M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586520d1fd2d4bf99029f24899278c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0b09dafcb84f3c960b3f27f87f08ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0f874c11584306a1dfe96f19be6168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991e4a7f903a4ccb84a12170d72ec4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d10a7be0a14a4f8792558f208d1d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = CrossEncoder('cross-encoder/stsb-roberta-base')\n",
    "\n",
    "sentence_pairs = []\n",
    "for sentence1, sentence2 in zip(stsb_test['sentence1'], stsb_test['sentence2']):\n",
    "    sentence_pairs.append([sentence1, sentence2])\n",
    "    \n",
    "stsb_test['SBERT CrossEncoder_score'] = model.predict(sentence_pairs, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "negative-moderator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.477538\n",
       "1       0.837390\n",
       "2       0.996481\n",
       "3       0.955392\n",
       "4       0.311554\n",
       "          ...   \n",
       "1374    0.186893\n",
       "1375    0.105753\n",
       "1376    0.224270\n",
       "1377    0.002297\n",
       "1378    0.119692\n",
       "Name: SBERT CrossEncoder_score, Length: 1379, dtype: float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsb_test['SBERT CrossEncoder_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-weight",
   "metadata": {},
   "source": [
    "## SBERT Bi-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "normal-procedure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ad0ff8269045289002e7d4e0dbe6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/868 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c32ac35032e4804a28ef42a008723af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792994822a744685885e3e2fa9ef8449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2877e1bb331540edbb600610dded0187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/588 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff391223726e4d4787524a7a74a10aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57e3fb2f4c34939833885dc2e02c4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf689bdb681413ca32068b4c5a3e4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a3fd928f104a70b2b152146c355d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374f5b3a0826460e9624f24334e0b8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92b749adaa3486488192bcaf1cc0bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c870a2c0504c8dbe89c5b1eca05bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c8ec1293624ff59e8220cc55ed97d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d6de01e8304a109daa7dbbe8180a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3007989c60b400ab18ee5509294e031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = SentenceTransformer('stsb-mpnet-base-v2')\n",
    "\n",
    "# Generate Embeddings\n",
    "sentence1_emb = model.encode(stsb_test['sentence1'], show_progress_bar=True)\n",
    "sentence2_emb = model.encode(stsb_test['sentence2'], show_progress_bar=True)\n",
    "\n",
    "# Cosine Similarity\n",
    "stsb_test['SBERT BiEncoder_cosine_score'] = cos_sim(sentence1_emb, sentence2_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "shaped-strip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.653581\n",
       "1       0.825622\n",
       "2       0.970068\n",
       "3       0.976946\n",
       "4       0.471990\n",
       "          ...   \n",
       "1374    0.278521\n",
       "1375    0.238014\n",
       "1376    0.344677\n",
       "1377    0.011115\n",
       "1378    0.060945\n",
       "Name: SBERT BiEncoder_cosine_score, Length: 1379, dtype: float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsb_test['SBERT BiEncoder_cosine_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-segment",
   "metadata": {},
   "source": [
    "## SimCSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Supervised ##########\n",
    "# Load the pre-trained model\n",
    "model = SentenceTransformer('princeton-nlp/sup-simcse-roberta-large')\n",
    "\n",
    "# Generate Embeddings\n",
    "sentence1_emb = model.encode(stsb_test['sentence1'], show_progress_bar=True)\n",
    "sentence2_emb = model.encode(stsb_test['sentence2'], show_progress_bar=True)\n",
    "\n",
    "# Cosine Similarity\n",
    "stsb_test['SimCSE Supervised_cosine_score'] = cos_sim(sentence1_emb, sentence2_emb)\n",
    "\n",
    "\n",
    "########## Un-Supervised ##########\n",
    "# Load the pre-trained model\n",
    "model = SentenceTransformer('princeton-nlp/unsup-simcse-roberta-large')\n",
    "\n",
    "# Generate Embeddings\n",
    "sentence1_emb = model.encode(stsb_test['sentence1'], show_progress_bar=True)\n",
    "sentence2_emb = model.encode(stsb_test['sentence2'], show_progress_bar=True)\n",
    "\n",
    "# Cosine Similarity\n",
    "stsb_test['SimCSE Unsupervised_cosine_score'] = cos_sim(sentence1_emb, sentence2_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-detail",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pickle\n",
    "openai.api_key = 'update_your_openai_API_key_here'\n",
    "\n",
    "if os.path.exists('../data/nlp/davinci_emb.pkl'):\n",
    "    print('Loading Davinci Embeddings')\n",
    "    with open('../data/nlp/davinci_emb.pkl', 'rb') as f:\n",
    "        davinci_emb = pickle.load(f)\n",
    "else:\n",
    "    print('Querying Davinci Embeddings')\n",
    "    davinci_emb = {}\n",
    "    engine='text-similarity-davinci-001'\n",
    "\n",
    "    unique_sentences = list(set(stsb_test['sentence1'].values.tolist() + stsb_test['sentence2'].values.tolist()))\n",
    "    for sentence in tqdm(unique_sentences):\n",
    "        if sentence not in davinci_emb.keys():\n",
    "            davinci_emb[sentence] = openai.Embedding.create(input = [sentence], \n",
    "                                                            engine=engine)['data'][0]['embedding']\n",
    "    # Save embeddings to file      \n",
    "    with open('../data/nlp/davinci_emb.pkl', 'wb') as f:\n",
    "        pickle.dump(davinci_emb, f)\n",
    "\n",
    "# Generate Embeddings\n",
    "sentence1_emb = [davinci_emb[sentence] for sentence in stsb_test['sentence1']]\n",
    "sentence2_emb = [davinci_emb[sentence] for sentence in stsb_test['sentence2']]\n",
    "\n",
    "# Cosine Similarity\n",
    "stsb_test['OpenAI Davinci_cosine_score'] = cos_sim(sentence1_emb, sentence2_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-platform",
   "metadata": {},
   "source": [
    "## Result & Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cols = [col for col in stsb_test.columns if '_score' in col]\n",
    "\n",
    "# Spearman Rank Correlation\n",
    "spearman_rank_corr = stsb_test[score_cols].corr(method='spearman').iloc[1:, 0:1]*100\n",
    "spearman_rank_corr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-romantic",
   "metadata": {},
   "source": [
    "### Visually plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "nrows = 4\n",
    "ncols = 3\n",
    "plot_array = np.arange(0, nrows*ncols).reshape(nrows, ncols)\n",
    "subplot_titles = [f'{row.Index.split(\"_\")[0]}: {row.similarity_score:.2f}' for row in spearman_rank_corr.itertuples()]\n",
    "fig = make_subplots(rows=nrows, cols=ncols, subplot_titles=subplot_titles)\n",
    "\n",
    "for index, score in enumerate(spearman_rank_corr.index):\n",
    "    row, col = np.argwhere(plot_array == index)[0]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=stsb_test[score_cols[0]], \n",
    "            y=stsb_test[score],\n",
    "            mode='markers',\n",
    "        ),\n",
    "        row=row+1, col=col+1\n",
    "    )\n",
    "fig.update_layout(height=700, width=1000, title_text='Spearman Rank Correlation (ρ × 100)', showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-senior",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
