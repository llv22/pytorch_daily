{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "photographic-subscriber",
   "metadata": {},
   "source": [
    "# Transformer via torch\n",
    "\n",
    "Original paper: \n",
    "* https://arxiv.org/pdf/1706.03762.pdf  \n",
    "\n",
    "Paper and implementation: \n",
    "* https://paperswithcode.com/paper/attention-is-all-you-need  \n",
    "\n",
    "Dataset:  \n",
    "* https://paperswithcode.com/dataset/wmt-2014  \n",
    "* explore dataset here https://huggingface.co/datasets/viewer/?dataset=wmt19  \n",
    "\n",
    "We use https://huggingface.co/datasets/wmt14 for transformer purpose.  \n",
    "More see in https://huggingface.co/models  \n",
    "\n",
    "Reference implementation: \n",
    "* Baseline provided by pytorch: https://pytorch.org/hub/pytorch_fairseq_translation/  \n",
    "* https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py\n",
    "* https://github.com/jadore801120/attention-is-all-you-need-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "engaged-reggae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 0 caching in ~/.cache/huggingface, 1 in ~/workspace/dataset/cache, or 2 in ../../.cache: \n",
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ac5c8904434442aab406dca018aa21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wmt14/de-en to /home/i058959/workspace/dataset/cache/wmt14/de-en/1.0.0/6aa64c5c4f2c1c217718c6d6266aad92d1229e761c57379c53752b8c0e55c93b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d443ababcb0d4699bf8cf30bb813c89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0e8122c4c84a2b86d5ff904c25fd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7232a9c46cd46b5a61bb6bd2ce6ef25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wmt14 downloaded and prepared to /home/i058959/workspace/dataset/cache/wmt14/de-en/1.0.0/6aa64c5c4f2c1c217718c6d6266aad92d1229e761c57379c53752b8c0e55c93b. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344f59d589d94c76a87472bf72749250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how to load dataset, refer to https://huggingface.co/docs/datasets/quicktour.html\n",
    "# https://paperswithcode.com/paper/incorporating-bert-into-neural-machine-1\n",
    "# https://colab.research.google.com/github/huggingface/datasets/blob/master/notebooks/Overview.ipynb\n",
    "from datasets import list_datasets, load_dataset, list_metrics, load_metric\n",
    "\n",
    "complete=False\n",
    "while not complete:\n",
    "    try:\n",
    "        choice=int(input(\"Enter 0 caching in ~/.cache/huggingface, 1 in ~/workspace/dataset/cache, or 2 in ../../.cache: \\n\"))\n",
    "        if choice in range(3):\n",
    "            complete=True\n",
    "    except ValueError:\n",
    "        pass\n",
    "        \n",
    "# alternatively we can also use wmt19, but as its large size, currently use a smaller one\n",
    "if choice == 0:\n",
    "    dataset_wmt14_de_en = load_dataset('wmt14', 'de-en')\n",
    "elif choice == 1:\n",
    "    dataset_wmt14_de_en = load_dataset('wmt14', 'de-en', cache_dir='~/workspace/dataset/cache')\n",
    "else:\n",
    "    dataset_wmt14_de_en = load_dataset('wmt14', 'de-en', cache_dir='../../.cache/huggingface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-nothing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
