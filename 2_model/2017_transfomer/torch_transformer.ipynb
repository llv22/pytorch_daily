{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "photographic-subscriber",
   "metadata": {},
   "source": [
    "# Transformer via torch\n",
    "\n",
    "Original paper: \n",
    "* https://arxiv.org/pdf/1706.03762.pdf  \n",
    "\n",
    "Paper and implementation: \n",
    "* https://paperswithcode.com/paper/attention-is-all-you-need  \n",
    "\n",
    "Dataset:  \n",
    "* https://paperswithcode.com/dataset/wmt-2014  \n",
    "* explore dataset here https://huggingface.co/datasets/viewer/?dataset=wmt19  \n",
    "\n",
    "We use https://huggingface.co/datasets/wmt14 for transformer purpose.  \n",
    "More see in https://huggingface.co/models  \n",
    "\n",
    "Reference implementation: \n",
    "* Baseline provided by pytorch: https://pytorch.org/hub/pytorch_fairseq_translation/  \n",
    "* https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py\n",
    "* https://github.com/jadore801120/attention-is-all-you-need-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "engaged-reggae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wmt14/de-en (download: 1.58 GiB, generated: 1.27 GiB, post-processed: Unknown size, total: 2.85 GiB) to /Users/i058959/.cache/huggingface/datasets/wmt14/de-en/1.0.0/3d7d25048da28a2f2a8dda5ca306bdc4affcf02bbcb3d277cfe2d5d7b1d71ebc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 658M/658M [05:16<00:00, 2.08MB/s]\n",
      " 20%|██        | 1/5 [05:20<21:23, 320.85s/it]"
     ]
    }
   ],
   "source": [
    "# how to load dataset, refer to https://huggingface.co/docs/datasets/quicktour.html\n",
    "# https://paperswithcode.com/paper/incorporating-bert-into-neural-machine-1\n",
    "# https://colab.research.google.com/github/huggingface/datasets/blob/master/notebooks/Overview.ipynb\n",
    "from datasets import list_datasets, load_dataset, list_metrics, load_metric\n",
    "\n",
    "complete=False\n",
    "while not complete:\n",
    "    try:\n",
    "        choice=int(input(\"Enter 0 caching in ~/.cache/huggingface or 1 in ~/workspace/dataset/cache: \\n\"))\n",
    "        if choice in range(2):\n",
    "            complete=True\n",
    "    except ValueError:\n",
    "        pass\n",
    "        \n",
    "# alternatively we can also use wmt19, but as its large size, currently use a smaller one\n",
    "if not choice:\n",
    "    dataset_wmt14_de_en = load_dataset('wmt14', 'de-en')\n",
    "else:\n",
    "    dataset_wmt14_de_en = load_dataset('wmt14', 'de-en', cache_dir='~/workspace/dataset/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-nothing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
